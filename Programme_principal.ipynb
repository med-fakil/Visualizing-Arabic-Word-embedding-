{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "import gensim\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.fasttext import FastText\n",
    "from  sklearn.decomposition  import  PCA \n",
    "from matplotlib  import  pyplot\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib  import  pyplot\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('AJGT.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Sentiment'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[df.iloc[sentence,1] for sentence in range(0,1800)]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_arabic_words(string):\n",
    "    return ' '.join([word for word in string.split() if not re.findall(\n",
    "        r'[^\\s\\u0621\\u0622\\u0623\\u0624\\u0625\\u0626\\u0627\\u0628\\u0629\\u062A\\u062B\\u062C\\u062D\\u062E\\u062F\\u0630\\u0631\\u0632\\u0633\\u0634\\u0635\\u0636\\u0637\\u0638\\u0639\\u063A\\u0640\\u0641\\u0642\\u0643\\u0644\\u0645\\u0646\\u0647\\u0648\\u0649\\u064A]',\n",
    "        word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean=[remove_non_arabic_words(sentence) for sentence in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = [donne for donne in data_clean if donne not in stopwords.words('arabic')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in data_final:\n",
    "    words = [word for word in word_tokenize(text)]\n",
    "    corpus.append(words)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining values for parameters\n",
    "embedding_size = 100\n",
    "window_size = 5\n",
    "min_word = 5\n",
    "down_sampling = 1e-2\n",
    " \n",
    "fast_Text_model = FastText(corpus,\n",
    "                      size=embedding_size,\n",
    "                      window=window_size,\n",
    "                      min_count=min_word,\n",
    "                      sample=down_sampling,\n",
    "                      workers = 4,\n",
    "                      sg=1,\n",
    "                      iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_Text_model.save(\"model_fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne plot for below word\n",
    "# for_word = 'food'\n",
    "def tsne_plot(for_word, w2v_model):\n",
    "    # trained fastText model dimention\n",
    "    dim_size = w2v_model.wv.vectors.shape[1]\n",
    " \n",
    "    arrays = np.empty((0, dim_size), dtype='f')\n",
    "    word_labels = [for_word]\n",
    "    color_list  = ['red']\n",
    " \n",
    "    # adds the vector of the query word\n",
    "    arrays = np.append(arrays, w2v_model.wv.__getitem__([for_word]), axis=0)\n",
    " \n",
    "    # gets list of most similar words\n",
    "    sim_words = w2v_model.wv.most_similar(for_word, topn=10)\n",
    " \n",
    "    # adds the vector for each of the closest words to the array\n",
    "    for wrd_score in sim_words:\n",
    "        wrd_vector = w2v_model.wv.__getitem__([wrd_score[0]])\n",
    "        word_labels.append(wrd_score[0])\n",
    "        color_list.append('green')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    " \n",
    "    #---------------------- Apply PCA and tsne to reduce dimention --------------\n",
    " \n",
    "    # fit 2d PCA model to the similar word vectors\n",
    "    model_pca = PCA(n_components = 10).fit_transform(arrays)\n",
    " \n",
    "    # Finds 2d coordinates t-SNE\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(model_pca)\n",
    " \n",
    "    # Sets everything up to plot\n",
    "    df_plot = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
    "                       'y': [y for y in Y[:, 1]],\n",
    "                       'words_name': word_labels,\n",
    "                       'words_color': color_list})\n",
    "    #------------------------- tsne plot Python -----------------------------------\n",
    " \n",
    "    # plot dots with color and position\n",
    "    plot_dot = sns.regplot(data=df_plot,\n",
    "                     x=\"x\",\n",
    "                     y=\"y\",\n",
    "                     fit_reg=False,\n",
    "                     marker=\"o\",\n",
    "                     scatter_kws={'s': 40,\n",
    "                                  'facecolors': df_plot['words_color']\n",
    "                                 }\n",
    "                    )\n",
    "    \n",
    " \n",
    "    # Adds annotations with color one by one with a loop\n",
    "    for line in range(0, df_plot.shape[0]):\n",
    "         plot_dot.text(df_plot[\"x\"][line],\n",
    "                 df_plot['y'][line],\n",
    "                 '  ' + df_plot[\"words_name\"][line].title(),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='bottom', size='medium',\n",
    "                 color=df_plot['words_color'][line],\n",
    "                 weight='normal'\n",
    "                ).set_size(15)\n",
    " \n",
    " \n",
    "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    " \n",
    "    plt.title('t-SNE visualization for word \"{}'.format(for_word.title()) +'\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(for_word='الاسلام', w2v_model=fast_Text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(fast_Text_model,'word embedding_model.ml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
